import cv2
import numpy as np
import adafruit_pca9685
import board
import busio
import time
import math

# Initialize the servo controller
i2c_bus = busio.I2C(board.SCL, board.SDA)
pca = adafruit_pca9685.PCA9685(i2c_bus)
pca.frequency = 50

# Define the servo parameters
servo_min = 150  # Min pulse length out of 4096
servo_max = 600  # Max pulse length out of 4096
servo_range = servo_max - servo_min

# Define the link lengths of the robotic arm
l1 = 0.2
l2 = 0.2
l3 = 0.15
l4 = 0.1

# Initialize the servo motor objects
kit = adafruit_pca9685.servo.Servo(pca.channels[0])
kit_1 = adafruit_pca9685.servo.Servo(pca.channels[1])
kit_2 = adafruit_pca9685.servo.Servo(pca.channels[2])
kit_3 = adafruit_pca9685.servo.Servo(pca.channels[3])
kit_4 = adafruit_pca9685.servo.Servo(pca.channels[4])
kit_5 = adafruit_pca9685.servo.Servo(pca.channels[5])

# Define the colors to be detected
green_lower = np.array([35, 80, 80])
green_upper = np.array([65, 255, 255])
red_lower = np.array([0, 100, 100])
red_upper = np.array([5, 255, 255])

# Start the video capture
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

while True:
    # Read a frame from the video capture
    ret, frame = cap.read()

    # Flip the frame horizontally for intuitive movement control
    frame = cv2.flip(frame, 1)

    # Convert the frame to the HSV color space
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # Threshold the frame to get only the green and red colors
    mask_green = cv2.inRange(hsv, green_lower, green_upper)
    mask_red = cv2.inRange(hsv, red_lower, red_upper)
    mask = mask_green + mask_red

    # Find the contours in the binary image
    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

    # Extract the contours of the plastic bottles and tin cans
    bottle_contours = [contour for contour in contours if cv2.contourArea(contour) > 1000 and cv2.contourArea(contour) < 20000 and len(cv2.approxPolyDP(contour, 0.01 * cv2.arcLength(contour, True), True)) >= 5]
    tin_contours = [contour for contour in contours if cv2.contourArea(contour) > 1000 and cv2.contourArea(contour) < 20000 and len(cv2.approxPolyDP(contour, 0.01 * cv2.arcLength(contour, True), True)) < 5]

        # Sort the bottle and tin contours based on their positions
        if len(bottle_contours) > 0:
            bottle_center = np.mean([cv2.minEnclosingCircle(contour)[0] for contour in bottle_contours], axis=0)
            bottle_contours = sorted(bottle_contours, key=lambda x: math.sqrt((cv2.minEnclosingCircle(x)[0][0] - bottle_center[0]) ** 2 + (cv2.minEnclosingCircle(x)[0][1] - bottle_center[1]) ** 2))
        if len(tin_contours) > 0:
            tin_center = np.mean([cv2.minEnclosingCircle(contour)[0] for contour in tin_contours], axis=0)
            tin_contours = sorted(tin_contours, key=lambda x: math.sqrt((cv2.minEnclosingCircle(x)[0][0] - tin_center[0]) ** 2 + (cv2.minEnclosingCircle(x)[0][1] - tin_center[1]) ** 2))

        # Control the robotic arm based on the detected objects
        if len(bottle_contours) > 0:
            bottle_center = cv2.minEnclosingCircle(bottle_contours[0])[0]
            x = bottle_center[0] / 640
            y = bottle_center[1] / 480
            z = 0.15
            theta1 = math.atan2(y - l1, x)
            d = math.sqrt((x ** 2) + ((y - l1) ** 2))
            a = z - l4
            b = d - l2
            c = math.sqrt((a ** 2) + (b ** 2))
            alpha = math.atan2(a, b)
            beta = math.acos(((l3 ** 2) - (l2 ** 2) - (c ** 2) - (l4 ** 2)) / (-2 * l2 * c))
            theta2 = alpha - beta
            theta3 = math.acos(((c ** 2) - (l3 ** 2) - (l4 ** 2)) / (-2 * l3 * l4))
            theta4 = math.pi - theta2 - theta3
            kit.angle = int((theta1 * 180 / math.pi) * servo_range / 180 + servo_min)
            kit_1.angle = int((theta2 * 180 / math.pi) * servo_range / 180 + servo_min)
            kit_2.angle = int((theta3 * 180 / math.pi) * servo_range / 180 + servo_min)
            kit_3.angle = int((theta4 * 180 / math.pi) * servo_range / 180 + servo_min)
            time.sleep(0.5)
            kit_4.angle = servo_min
            time.sleep(0.5)
            kit_4.angle = servo_max
            time.sleep(0.5)
        elif len(tin_contours) > 0:
            tin_center = cv2.minEnclosingCircle(tin_contours[0])[0]
            x = tin_center[0] / 640
            y = tin_center[1] / 480
            z = 0.15
            theta1 = math.atan2(y - l1, x)
            d = math.sqrt((x ** 2) + ((y - l1) ** 2))
            a = z - l4
            b = d - l2
            c = math.sqrt((a ** 2) + (b ** 2))
            alpha = math.atan2(a, b)
            beta = math.acos(((l3 ** 2) - (l2 ** 2) - (c ** 2) - (l4 ** 2)) / (-2 * l2 * c))
            theta2 = alpha - beta
            theta3 = math.acos(((c ** 2) - (l3 ** 2) - (l4 ** 2)) / (-2 * l3 * l4))
            theta4 = math.pi - theta2 - theta3
            kit.angle = int((theta1 * 180 / math.pi) * servo_range / 180 + servo_min)
            kit_1.angle = int((theta2 * 180 / math.pi) * servo_range / 180 + servo_min)
            kit_2.angle = int((theta3 * 180 / math.pi) * servo_range / 180 + servo_min)
            kit_3.angle = int((theta4 * 180 / math.pi) * servo_range / 180 + servo_min)
            time.sleep(0.5)
            kit_4.angle = servo_min
            time.sleep(0.5)
            kit_4.angle = servo_max
            time.sleep(0.5)
        
        # Display the processed frame
        cv2.imshow("Frame", frame)
        
        # Exit the loop if the 'q' key is pressed
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Release the video capture and close all windows
    cap.release()
    cv2.destroyAllWindows()


